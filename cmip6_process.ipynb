{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5bbe4442-f9d3-448d-a90a-b7565d481559",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import cmocean as cmo\n",
    "import xarray as xr\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "mpl.rcParams['figure.figsize'] = 12, 8\n",
    "mpl.rcParams['font.size'] = 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "38aae33e-9edc-452c-9e53-3554697826f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"EC-Earth3\"] #, \"CanESM5\", \"ACCESS-ESM1-5\", \"EC-Earth3\", \"MIROC-ES2L\", \"MPI-ESM1-2-LR\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c4ff545-bb6c-41d2-8340-b20b5a59b5d7",
   "metadata": {},
   "source": [
    "# CMIP6 SSP585"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b2088110-ab9d-4ad4-b798-7b08d64f6589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin processing for model: EC-Earth3 \n",
      "\n",
      "  # ensemble members = 35\n",
      "  Area filename: /glade/scratch/zespinosa/cmip6/ssp585/area/areacello_Ofx_EC-Earth3_ssp585_r1i1p1f1_gn.nc\n",
      "  Spatial dimension names: ('j', 'i')\n",
      "  Index of middle latitude (rounded): 146\n",
      "  Latitudes start from: -78.39350128173828\n",
      "  Beginning siarea calculation . . .\n",
      "  Done with siarea calculation\n",
      "  Saving to cdf . . .\n",
      "  Arctic filename: siarea_nh_EC-Earth3.nc\n",
      "  Antarctic filename: siarea_sh_EC-Earth3.nc\n",
      "  Done\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    print(f\"Begin processing for model: {model} \\n\")\n",
    "    droot = '/glade/scratch/zespinosa/cmip6/ssp585/data/v_siconc_f_mon_e_ssp585_s_' + model + '/processed'\n",
    "    if model == \"MIROC-ES2L\": dfiles = sorted(glob(droot + '/*i1p1f1_gn_201501-210012.nc')) \n",
    "    else: dfiles = sorted(glob(droot + '/*i1p1f1_gn_201501-210012.nc'))\n",
    " \n",
    "    print(f\"  # ensemble members = {len(dfiles)}\")\n",
    "    \n",
    "    mfds = xr.open_mfdataset(dfiles, combine='nested', concat_dim='ensmem')\n",
    "    mfds = mfds.assign_coords({'ensmem': ('ensmem', np.arange(0, len(dfiles)))})\n",
    "    \n",
    "    # Get grid cell area file\n",
    "    ddir = '/glade/scratch/zespinosa/cmip6/ssp585/area/'\n",
    "    dfile = sorted(glob(os.path.join(ddir, \"areacello*\"+model+\"*.nc\")))[0]\n",
    "    print(f\"  Area filename: {dfile}\")\n",
    "    ncf = os.path.join(ddir, dfile)\n",
    "    ds = xr.open_dataset(ncf)\n",
    "    \n",
    "    area = ds['areacello']\n",
    "    siconc = mfds['siconc']/100\n",
    "    \n",
    "    # Compute sea ice area in each grid cell\n",
    "    siarea = siconc*area.data[None, None, :, :]\n",
    "    siarea = siarea.rename('siarea')\n",
    "    \n",
    "    # Get name of lat and lon dimensio ns, these differ by model\n",
    "    spatial_dims = siarea.dims[-2:]\n",
    "    print(f\"  Spatial dimension names: {spatial_dims}\")\n",
    "    \n",
    "    # Get index of approximate middle of latitudes to separate Arctic and Antarctic\n",
    "    lat_mid_index = int(siarea.shape[2]/2)\n",
    "    print(f\"  Index of middle latitude (rounded): {lat_mid_index}\")\n",
    "    \n",
    "    # Get first latitude to determine if lats start in Arctic or Antarctic\n",
    "    # First need to get name of latitude variable, differs by model\n",
    "    possible_latnames = [\"lat\", \"latitude\", \"nav_lat\"]\n",
    "    for name in possible_latnames:\n",
    "        if name in ds.coords:\n",
    "            latname = name\n",
    "  \n",
    "    lat0 = siarea[latname][0, 0].compute()\n",
    "        \n",
    "    print(f\"  Latitudes start from: {lat0.data}\")\n",
    "    print(\"  Beginning siarea calculation . . .\")\n",
    "    \n",
    "    if lat0 < 0: # If latitudes start from Antarctica\n",
    "        siarea_nh = siarea[:, :, lat_mid_index:, :].sum(spatial_dims) #.compute()\n",
    "        siarea_sh = siarea[:, :, :lat_mid_index, :].sum(spatial_dims) #.compute()\n",
    "    else: # If latitudes start from Arctic\n",
    "        siarea_nh = siarea[:, :, :lat_mid_index, :].sum(spatial_dims) #.compute()\n",
    "        siarea_sh = siarea[:, :, lat_mid_index:, :].sum(spatial_dims) #.compute()\n",
    "    \n",
    "    print(\"  Done with siarea calculation\")\n",
    "    print(\"  Saving to cdf . . .\")\n",
    "    dout_nh = 'siarea_nh_'+model+'.nc'\n",
    "    dout_sh = 'siarea_sh_'+model+'.nc'\n",
    "    print(f\"  Arctic filename: {dout_nh}\")\n",
    "    print(f\"  Antarctic filename: {dout_sh}\")\n",
    "    \n",
    "    siarea_nh.to_dataset().to_netcdf(dout_nh)\n",
    "    siarea_sh.to_dataset().to_netcdf(dout_sh)\n",
    "      \n",
    "    print(\"  Done\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf89cc09-bbd3-4841-8140-538b0fdcf837",
   "metadata": {},
   "source": [
    "# CMIP6 Historical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1a714b03-a98b-46ef-814b-9cd59dc26aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmip6Historical = [\"ACCESS-ESM1-5\", \"MPI-ESM1-2-LR\", \"EC-Earth3\"] #\"MIROC-ES2L\", \"CanESM5\", \"ACCESS-ESM1-5\", \"MPI-ESM1-2-LR\", \"EC-Earth3\", "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6a17a59c-019d-401b-b2f0-1c02e7dd5a82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin processing for model: ACCESS-ESM1-5 \n",
      "\n",
      "/glade/scratch/zespinosa/cmip6/hist/data/v_siconc_f_mon_e_historical_s_ACCESS-ESM1-5\n",
      "  # ensemble members = 40\n",
      "  Area filename: /glade/scratch/zespinosa/cmip6/ssp585/area/areacello_Ofx_ACCESS-ESM1-5_ssp585_r1i1p1f1_gn.nc\n",
      "  Spatial dimension names: ('j', 'i')\n",
      "  Index of middle latitude (rounded): 150\n",
      "  Latitudes start from: -77.87662506103516\n",
      "  Beginning siarea calculation . . .\n",
      "  Done with siarea calculation\n",
      "  Saving to tcdf . . .\n",
      "  Arctic filename: siarea_nh_historical_ACCESS-ESM1-5.nc\n",
      "  Antarctic filename: siarea_sh_historical_ACCESS-ESM1-5.nc\n",
      "  Done\n",
      "\n",
      "Begin processing for model: MPI-ESM1-2-LR \n",
      "\n",
      "/glade/scratch/zespinosa/cmip6/hist/data/v_siconc_f_mon_e_historical_s_MPI-ESM1-2-LR/processed\n",
      "  # ensemble members = 30\n",
      "  Area filename: /glade/scratch/zespinosa/cmip6/ssp585/area/areacello_Ofx_MPI-ESM1-2-LR_ssp585_r1i1p1f1_gn.nc\n",
      "  Spatial dimension names: ('j', 'i')\n",
      "  Index of middle latitude (rounded): 110\n",
      "  Latitudes start from: 76.35550435427294\n",
      "  Beginning siarea calculation . . .\n",
      "  Done with siarea calculation\n",
      "  Saving to tcdf . . .\n",
      "  Arctic filename: siarea_nh_historical_MPI-ESM1-2-LR.nc\n",
      "  Antarctic filename: siarea_sh_historical_MPI-ESM1-2-LR.nc\n",
      "  Done\n",
      "\n",
      "Begin processing for model: EC-Earth3 \n",
      "\n",
      "/glade/scratch/zespinosa/cmip6/hist/data/v_siconc_f_mon_e_historical_s_EC-Earth3/processed\n",
      "  # ensemble members = 68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glade/u/apps/ch/opt/python/3.7.12/gnu/9.1.0/pkg-library/20211005/lib/python3.7/site-packages/xarray/core/indexing.py:1226: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n",
      "/glade/u/apps/ch/opt/python/3.7.12/gnu/9.1.0/pkg-library/20211005/lib/python3.7/site-packages/xarray/core/indexing.py:1226: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n",
      "/glade/u/apps/ch/opt/python/3.7.12/gnu/9.1.0/pkg-library/20211005/lib/python3.7/site-packages/xarray/core/indexing.py:1226: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n",
      "/glade/u/apps/ch/opt/python/3.7.12/gnu/9.1.0/pkg-library/20211005/lib/python3.7/site-packages/xarray/core/indexing.py:1226: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n",
      "/glade/u/apps/ch/opt/python/3.7.12/gnu/9.1.0/pkg-library/20211005/lib/python3.7/site-packages/xarray/core/indexing.py:1226: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n",
      "/glade/u/apps/ch/opt/python/3.7.12/gnu/9.1.0/pkg-library/20211005/lib/python3.7/site-packages/xarray/core/indexing.py:1226: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n",
      "/glade/u/apps/ch/opt/python/3.7.12/gnu/9.1.0/pkg-library/20211005/lib/python3.7/site-packages/xarray/core/indexing.py:1226: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n",
      "/glade/u/apps/ch/opt/python/3.7.12/gnu/9.1.0/pkg-library/20211005/lib/python3.7/site-packages/xarray/core/indexing.py:1226: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n",
      "/glade/u/apps/ch/opt/python/3.7.12/gnu/9.1.0/pkg-library/20211005/lib/python3.7/site-packages/xarray/core/indexing.py:1226: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n",
      "/glade/u/apps/ch/opt/python/3.7.12/gnu/9.1.0/pkg-library/20211005/lib/python3.7/site-packages/xarray/core/indexing.py:1226: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n",
      "/glade/u/apps/ch/opt/python/3.7.12/gnu/9.1.0/pkg-library/20211005/lib/python3.7/site-packages/xarray/core/indexing.py:1226: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n",
      "/glade/u/apps/ch/opt/python/3.7.12/gnu/9.1.0/pkg-library/20211005/lib/python3.7/site-packages/xarray/core/indexing.py:1226: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n",
      "/glade/u/apps/ch/opt/python/3.7.12/gnu/9.1.0/pkg-library/20211005/lib/python3.7/site-packages/xarray/core/indexing.py:1226: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n",
      "/glade/u/apps/ch/opt/python/3.7.12/gnu/9.1.0/pkg-library/20211005/lib/python3.7/site-packages/xarray/core/indexing.py:1226: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n",
      "/glade/u/apps/ch/opt/python/3.7.12/gnu/9.1.0/pkg-library/20211005/lib/python3.7/site-packages/xarray/core/indexing.py:1226: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n",
      "/glade/u/apps/ch/opt/python/3.7.12/gnu/9.1.0/pkg-library/20211005/lib/python3.7/site-packages/xarray/core/indexing.py:1226: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n",
      "/glade/u/apps/ch/opt/python/3.7.12/gnu/9.1.0/pkg-library/20211005/lib/python3.7/site-packages/xarray/core/indexing.py:1226: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n",
      "/glade/u/apps/ch/opt/python/3.7.12/gnu/9.1.0/pkg-library/20211005/lib/python3.7/site-packages/xarray/core/indexing.py:1226: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n",
      "/glade/u/apps/ch/opt/python/3.7.12/gnu/9.1.0/pkg-library/20211005/lib/python3.7/site-packages/xarray/core/indexing.py:1226: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n",
      "/glade/u/apps/ch/opt/python/3.7.12/gnu/9.1.0/pkg-library/20211005/lib/python3.7/site-packages/xarray/core/indexing.py:1226: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n",
      "/glade/u/apps/ch/opt/python/3.7.12/gnu/9.1.0/pkg-library/20211005/lib/python3.7/site-packages/xarray/core/indexing.py:1226: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n",
      "/glade/u/apps/ch/opt/python/3.7.12/gnu/9.1.0/pkg-library/20211005/lib/python3.7/site-packages/xarray/core/indexing.py:1226: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n",
      "/glade/u/apps/ch/opt/python/3.7.12/gnu/9.1.0/pkg-library/20211005/lib/python3.7/site-packages/xarray/core/indexing.py:1226: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n",
      "/glade/u/apps/ch/opt/python/3.7.12/gnu/9.1.0/pkg-library/20211005/lib/python3.7/site-packages/xarray/core/indexing.py:1226: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n",
      "/glade/u/apps/ch/opt/python/3.7.12/gnu/9.1.0/pkg-library/20211005/lib/python3.7/site-packages/xarray/core/indexing.py:1226: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n",
      "/glade/u/apps/ch/opt/python/3.7.12/gnu/9.1.0/pkg-library/20211005/lib/python3.7/site-packages/xarray/core/indexing.py:1226: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n",
      "/glade/u/apps/ch/opt/python/3.7.12/gnu/9.1.0/pkg-library/20211005/lib/python3.7/site-packages/xarray/core/indexing.py:1226: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n",
      "/glade/u/apps/ch/opt/python/3.7.12/gnu/9.1.0/pkg-library/20211005/lib/python3.7/site-packages/xarray/core/indexing.py:1226: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n",
      "/glade/u/apps/ch/opt/python/3.7.12/gnu/9.1.0/pkg-library/20211005/lib/python3.7/site-packages/xarray/core/indexing.py:1226: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n",
      "/glade/u/apps/ch/opt/python/3.7.12/gnu/9.1.0/pkg-library/20211005/lib/python3.7/site-packages/xarray/core/indexing.py:1226: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n",
      "/glade/u/apps/ch/opt/python/3.7.12/gnu/9.1.0/pkg-library/20211005/lib/python3.7/site-packages/xarray/core/indexing.py:1226: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n",
      "/glade/u/apps/ch/opt/python/3.7.12/gnu/9.1.0/pkg-library/20211005/lib/python3.7/site-packages/xarray/core/indexing.py:1226: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n",
      "/glade/u/apps/ch/opt/python/3.7.12/gnu/9.1.0/pkg-library/20211005/lib/python3.7/site-packages/xarray/core/indexing.py:1226: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n",
      "/glade/u/apps/ch/opt/python/3.7.12/gnu/9.1.0/pkg-library/20211005/lib/python3.7/site-packages/xarray/core/indexing.py:1226: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n",
      "/glade/u/apps/ch/opt/python/3.7.12/gnu/9.1.0/pkg-library/20211005/lib/python3.7/site-packages/xarray/core/indexing.py:1226: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n",
      "/glade/u/apps/ch/opt/python/3.7.12/gnu/9.1.0/pkg-library/20211005/lib/python3.7/site-packages/xarray/core/indexing.py:1226: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n",
      "/glade/u/apps/ch/opt/python/3.7.12/gnu/9.1.0/pkg-library/20211005/lib/python3.7/site-packages/xarray/core/indexing.py:1226: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n",
      "/glade/u/apps/ch/opt/python/3.7.12/gnu/9.1.0/pkg-library/20211005/lib/python3.7/site-packages/xarray/core/indexing.py:1226: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n",
      "/glade/u/apps/ch/opt/python/3.7.12/gnu/9.1.0/pkg-library/20211005/lib/python3.7/site-packages/xarray/core/indexing.py:1226: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n",
      "/glade/u/apps/ch/opt/python/3.7.12/gnu/9.1.0/pkg-library/20211005/lib/python3.7/site-packages/xarray/core/indexing.py:1226: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n",
      "/glade/u/apps/ch/opt/python/3.7.12/gnu/9.1.0/pkg-library/20211005/lib/python3.7/site-packages/xarray/core/indexing.py:1226: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n",
      "/glade/u/apps/ch/opt/python/3.7.12/gnu/9.1.0/pkg-library/20211005/lib/python3.7/site-packages/xarray/core/indexing.py:1226: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n",
      "/glade/u/apps/ch/opt/python/3.7.12/gnu/9.1.0/pkg-library/20211005/lib/python3.7/site-packages/xarray/core/indexing.py:1226: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n",
      "/glade/u/apps/ch/opt/python/3.7.12/gnu/9.1.0/pkg-library/20211005/lib/python3.7/site-packages/xarray/core/indexing.py:1226: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n",
      "/glade/u/apps/ch/opt/python/3.7.12/gnu/9.1.0/pkg-library/20211005/lib/python3.7/site-packages/xarray/core/indexing.py:1226: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n",
      "/glade/u/apps/ch/opt/python/3.7.12/gnu/9.1.0/pkg-library/20211005/lib/python3.7/site-packages/xarray/core/indexing.py:1226: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n",
      "/glade/u/apps/ch/opt/python/3.7.12/gnu/9.1.0/pkg-library/20211005/lib/python3.7/site-packages/xarray/core/indexing.py:1226: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n",
      "/glade/u/apps/ch/opt/python/3.7.12/gnu/9.1.0/pkg-library/20211005/lib/python3.7/site-packages/xarray/core/indexing.py:1226: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n",
      "/glade/u/apps/ch/opt/python/3.7.12/gnu/9.1.0/pkg-library/20211005/lib/python3.7/site-packages/xarray/core/indexing.py:1226: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n",
      "/glade/u/apps/ch/opt/python/3.7.12/gnu/9.1.0/pkg-library/20211005/lib/python3.7/site-packages/xarray/core/indexing.py:1226: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Area filename: /glade/scratch/zespinosa/cmip6/ssp585/area/areacello_Ofx_EC-Earth3_ssp585_r1i1p1f1_gn.nc\n",
      "  Spatial dimension names: ('j', 'i')\n",
      "  Index of middle latitude (rounded): 146\n",
      "  Latitudes start from: -78.39350128173828\n",
      "  Beginning siarea calculation . . .\n",
      "  Done with siarea calculation\n",
      "  Saving to tcdf . . .\n",
      "  Arctic filename: siarea_nh_historical_EC-Earth3.nc\n",
      "  Antarctic filename: siarea_sh_historical_EC-Earth3.nc\n",
      "  Done\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model in cmip6Historical:\n",
    "    print(f\"Begin processing for model: {model} \\n\")\n",
    "    droot = '/glade/scratch/zespinosa/cmip6/hist/data/v_siconc_f_mon_e_historical_s_' + model\n",
    "    if model in [\"EC-Earth3\", \"MPI-ESM1-2-LR\"]: droot = droot + \"/processed\"\n",
    "    \n",
    "    print(droot)\n",
    "    if model == \"MIROC-ES2L\": dfiles = sorted(glob(droot + '/*i1p1f2_gn_185001-201412.nc')) \n",
    "    elif model == \"CanESM5\": dfiles = sorted(glob(droot + '/*i1p2f1_gn_185001-201412.nc'))\n",
    "    else: dfiles = sorted(glob(droot + '/*185001-201412.nc'))\n",
    " \n",
    "    print(f\"  # ensemble members = {len(dfiles)}\")\n",
    "    \n",
    "    mfds = xr.open_mfdataset(dfiles, combine='nested', concat_dim='ensmem')\n",
    "    mfds = mfds.assign_coords({'ensmem': ('ensmem', np.arange(0, len(dfiles)))})\n",
    "    \n",
    "    # Get grid cell area file\n",
    "    ddir = '/glade/scratch/zespinosa/cmip6/ssp585/area/'\n",
    "    dfile = sorted(glob(os.path.join(ddir, \"areacello*\"+model+\"*.nc\")))[0]\n",
    "    print(f\"  Area filename: {dfile}\")\n",
    "    ncf = os.path.join(ddir, dfile)\n",
    "    ds = xr.open_dataset(ncf)\n",
    "    \n",
    "    area = ds['areacello']\n",
    "    siconc = mfds['siconc']/100\n",
    "    \n",
    "    # Compute sea ice area in each grid cell\n",
    "    siarea = siconc*area.data[None, None, :, :]\n",
    "    siarea = siarea.rename('siarea')\n",
    "    \n",
    "    # Get name of lat and lon dimensio ns, these differ by model\n",
    "    spatial_dims = siarea.dims[-2:]\n",
    "    print(f\"  Spatial dimension names: {spatial_dims}\")\n",
    "    \n",
    "    # Get index of approximate middle of latitudes to separate Arctic and Antarctic\n",
    "    lat_mid_index = int(siarea.shape[2]/2)\n",
    "    print(f\"  Index of middle latitude (rounded): {lat_mid_index}\")\n",
    "    \n",
    "    # Get first latitude to determine if lats start in Arctic or Antarctic\n",
    "    # First need to get name of latitude variable, differs by model\n",
    "    possible_latnames = [\"lat\", \"latitude\", \"nav_lat\"]\n",
    "    for name in possible_latnames:\n",
    "        if name in ds.coords:\n",
    "            latname = name\n",
    "  \n",
    "    lat0 = siarea[latname][0, 0].compute()\n",
    "        \n",
    "    print(f\"  Latitudes start from: {lat0.data}\")\n",
    "    print(\"  Beginning siarea calculation . . .\")\n",
    "    \n",
    "    if lat0 < 0: # If latitudes start from Antarctica\n",
    "        siarea_nh = siarea[:, :, lat_mid_index:, :].sum(spatial_dims) #.compute()\n",
    "        siarea_sh = siarea[:, :, :lat_mid_index, :].sum(spatial_dims) #.compute()\n",
    "    else: # If latitudes start from Arctic\n",
    "        siarea_nh = siarea[:, :, :lat_mid_index, :].sum(spatial_dims) #.compute()\n",
    "        siarea_sh = siarea[:, :, lat_mid_index:, :].sum(spatial_dims) #.compute()\n",
    "    \n",
    "    print(\"  Done with siarea calculation\")\n",
    "    print(\"  Saving to tcdf . . .\")\n",
    "    dout_nh = 'siarea_nh_historical_'+model+'.nc'\n",
    "    dout_sh = 'siarea_sh_historical_'+model+'.nc'\n",
    "    print(f\"  Arctic filename: {dout_nh}\")\n",
    "    print(f\"  Antarctic filename: {dout_sh}\")\n",
    "    \n",
    "    # siarea_nh.to_netcdf(dout_nh)\n",
    "    siarea_sh.to_netcdf(dout_sh)\n",
    "      \n",
    "    print(\"  Done\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39bbcc4a-6e7c-4521-95ad-1f75d19d0406",
   "metadata": {},
   "source": [
    "# CMIP5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e573a1bd-f4ca-4b79-9759-e1c1a95d28f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmip5Models = [\n",
    "    (\"CanESM2\",\"\"),\n",
    "    (\"\", \"\"),\n",
    "    (\"\", \"\"),\n",
    "    (\"\", \"\"),\n",
    "    (\"\", \"\"),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5d10135a-ee19-424e-a9e6-6f99926de859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin processing for model: CanESM2 \n",
      "\n",
      "  # ensemble members = 50\n",
      "  Area filename: /glade/scratch/zespinosa/cmip5/area/areacello_fx_CanESM2_rcp85_r0i0p0.nc\n",
      "> \u001b[0;32m/glade/scratch/zespinosa/ipykernel_11480/855720209.py\u001b[0m(22)\u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     20 \u001b[0;31m    \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     21 \u001b[0;31m    \u001b[0;31m# Compute sea ice area in each grid cell\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 22 \u001b[0;31m    \u001b[0msiarea\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msiconc\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marea\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     23 \u001b[0;31m    \u001b[0msiarea\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msiarea\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'siarea'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     24 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  siconc.shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 1812, 64, 128)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  q\n"
     ]
    },
    {
     "ename": "BdbQuit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBdbQuit\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m/glade/scratch/zespinosa/ipykernel_11480/855720209.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m# Compute sea ice area in each grid cell\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0msiarea\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msiconc\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marea\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0msiarea\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msiarea\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'siarea'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/glade/scratch/zespinosa/ipykernel_11480/855720209.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m# Compute sea ice area in each grid cell\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0msiarea\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msiconc\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marea\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0msiarea\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msiarea\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'siarea'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/glade/u/apps/ch/opt/python/3.7.12/gnu/9.1.0/lib/python3.7/bdb.py\u001b[0m in \u001b[0;36mtrace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;31m# None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'line'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'call'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/glade/u/apps/ch/opt/python/3.7.12/gnu/9.1.0/lib/python3.7/bdb.py\u001b[0m in \u001b[0;36mdispatch_line\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbreak_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquitting\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mBdbQuit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_dispatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBdbQuit\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for model in cmip5Models:\n",
    "    print(f\"Begin processing for model: {model} \\n\")\n",
    "    droot = '/glade/collections/cdg/data/CLIVAR_LE/canesm2_lens/OImon/sic/'\n",
    "    dfiles = sorted(glob(droot + '/*195001-210012.nc'))\n",
    "    print(f\"  # ensemble members = {len(dfiles)}\")\n",
    "    \n",
    "    mfds = xr.open_mfdataset(dfiles, combine='nested', concat_dim='ensmem')\n",
    "    mfds = mfds.assign_coords({'ensmem': ('ensmem', np.arange(0, len(dfiles)))})\n",
    "    \n",
    "    # Get grid cell area file\n",
    "    ddir = '/glade/scratch/zespinosa/cmip5/area/'\n",
    "    dfile = sorted(glob(os.path.join(ddir, \"areacello*\"+model+\"*.nc\")))[0]\n",
    "    print(f\"  Area filename: {dfile}\")\n",
    "    ncf = os.path.join(ddir, dfile)\n",
    "    ds = xr.open_dataset(ncf)\n",
    "    \n",
    "    area = ds['areacello']\n",
    "    siconc = mfds['sic']/100\n",
    "    \n",
    "    import pdb; pdb.set_trace()\n",
    "    # Compute sea ice area in each grid cell\n",
    "    siarea = siconc*area.data[None, None, :, :]\n",
    "    siarea = siarea.rename('siarea')\n",
    "\n",
    "    # Get name of lat and lon dimensio ns, these differ by model\n",
    "    spatial_dims = siarea.dims[-2:]\n",
    "    print(f\"  Spatial dimension names: {spatial_dims}\")\n",
    "    \n",
    "    # Get index of approximate middle of latitudes to separate Arctic and Antarctic\n",
    "    lat_mid_index = int(siarea.shape[2]/2)\n",
    "    print(f\"  Index of middle latitude (rounded): {lat_mid_index}\")\n",
    "    \n",
    "    # Get first latitude to determine if lats start in Arctic or Antarctic\n",
    "    # First need to get name of latitude variable, differs by model\n",
    "    possible_latnames = [\"lat\", \"latitude\", \"nav_lat\"]\n",
    "    for name in possible_latnames:\n",
    "        if name in ds.coords:\n",
    "            latname = name\n",
    "  \n",
    "    lat0 = siarea[latname][0, 0].compute()\n",
    "        \n",
    "    print(f\"  Latitudes start from: {lat0.data}\")\n",
    "    print(\"  Beginning siarea calculation . . .\")\n",
    "    break\n",
    "    if lat0 < 0: # If latitudes start from Antarctica\n",
    "        siarea_nh = siarea[:, :, lat_mid_index:, :].sum(spatial_dims) #.compute()\n",
    "        siarea_sh = siarea[:, :, :lat_mid_index, :].sum(spatial_dims) #.compute()\n",
    "    else: # If latitudes start from Arctic\n",
    "        siarea_nh = siarea[:, :, :lat_mid_index, :].sum(spatial_dims) #.compute()\n",
    "        siarea_sh = siarea[:, :, lat_mid_index:, :].sum(spatial_dims) #.compute()\n",
    "    \n",
    "    print(\"  Done with siarea calculation\")\n",
    "    print(\"  Saving to tcdf . . .\")\n",
    "    dout_nh = 'siarea_nh_'+model+'.nc'\n",
    "    dout_sh = 'siarea_sh_'+model+'.nc'\n",
    "    print(f\"  Arctic filename: {dout_nh}\")\n",
    "    print(f\"  Antarctic filename: {dout_sh}\")\n",
    "    \n",
    "    siarea_nh.to_dataset().to_netcdf(dout_nh)\n",
    "    siarea_sh.to_dataset().to_netcdf(dout_sh)\n",
    "        \n",
    "    print(\"  Done\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484514e3-eff0-4164-875d-67ed2db21ee2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "74b44f82-18da-49dd-80d6-6b350b1f90a6",
   "metadata": {},
   "source": [
    "## Process CESM2 and CESM1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189f72b8-e677-446a-bc68-4dbe2d6c9d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "for exp in meta.keys():\n",
    "    droot = \"/glade/scratch/zespinosa/cmip6/scenarios/raw_data/data/\"\n",
    "    time = \"201501-210012.nc\"\n",
    "    if exp == \"historical\": \n",
    "        droot = \"/glade/scratch/zespinosa/cmip6/historical/raw_data/data/\"\n",
    "        time = \"185001-201412.nc\"\n",
    "    \n",
    "    for model in models:\n",
    "        print(f\"Begin Processing {exp} {model}\")\n",
    "        try: \n",
    "            fp = os.path.join(droot, f\"v_siconc_f_mon_e_{exp}_s_{model}\")\n",
    "\n",
    "            # Get ensemble members: \n",
    "            dfiles = sorted(glob(os.path.join(fp, '*.nc')))\n",
    "            import pdb; pdb.set_trace()\n",
    "            \n",
    "            if len(dfiles) != 0:\n",
    "                ensmem, nensmem = get_ensmem(dfiles)\n",
    "                meta[exp][model][\"ensmem\"] = ensmem\n",
    "                meta[exp][model][\"nensmem\"] = nensmem\n",
    "                print(\"Ensemble Members: \", ensmem)\n",
    "\n",
    "                # Combine files that do not span entire time-period and/or move into 'combined' folder\n",
    "                dest = os.path.join(fp, f\"{exp}_combined\")\n",
    "                if not os.path.exists(dest):\n",
    "                    os.mkdir(dest)\n",
    "                date = dfiles[0].split(\"_\")[-1]\n",
    "                if len(os.listdir(dest)) == 0:\n",
    "                    if date != time:\n",
    "                        for i in ensmem: \n",
    "                            sfiles = os.path.join(fp, f\"*_{model}_{exp}_r{i}i1p1f1*.nc\")\n",
    "                            sp = os.path.join(dest,f\"siconc_SImon_{model}_{exp}_r{i}i1p1f1_{time}\")\n",
    "                            print(f\"Creating {sp}\")\n",
    "                            os.system(f\"module load cdo; cdo -s mergetime {sfiles} {sp}\")\n",
    "                    else: \n",
    "                        print(f\"Moving files to {dest}\")\n",
    "                        for f in dfiles: \n",
    "                            os.system(f\"mv {f} {dest}\")\n",
    "        except Exception as err:\n",
    "            print(f\"{model} Failed! \\n {err}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
